{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# The Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "In the file dataset/data.csv, you will find a dataset containing news articles with the following columns:\n",
    "\n",
    "label: 0 if the news is fake, 1 if the news is real.\n",
    "title: The headline of the news article.\n",
    "text: The full content of the article.\n",
    "subject: The category or topic of the news.\n",
    "date: The publication date of the article.\n",
    "Your goal is to build a classifier that is able to distinguish between the two.\n",
    "\n",
    "Once you have a classifier built, then use it to predict the labels for dataset/validation_data.csv. Generate a new file where the label 2 has been replaced by 0 (fake) or 1 (real) according to your model. Please respect the original file format, do not include extra columns, and respect the column separator.\n",
    "\n",
    "Please ensure to split the data.csv into training and test datasets before using it for model training or evaluation.\n",
    "\n",
    "Guidance\n",
    "Like in a real life scenario, you are able to make your own choices and text treatment. Use the techniques you have learned and the common packages to process this data and classify the text.\n",
    "\n",
    "Deliverables\n",
    "Python Code: Provide well-documented Python code that conducts the analysis.\n",
    "Predictions: A csv file in the same format as validation_data.csv but with the predicted labels (0 or 1)\n",
    "Accuracy estimation: Provide the teacher with your estimation of how your model will perform.\n",
    "Presentation: You will present your model in a 10-minute presentation. Your teacher will provide further instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from nltk import pos_tag\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/training_data_lowercase.csv', sep='\\t', names=['labels', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Undertanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Its unique values are ',data['labels'].unique())\n",
    "print(print(data['labels'].describe()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.labels, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Basic cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_text(text: str) -> str:\n",
    "    if text is None:\n",
    "        return ''\n",
    "    text = str(text)\n",
    "    # Remove inline JavaScript/CSS\n",
    "    text = re.sub(r\"(?is)<script.*?>.*?</script>\", \" \", text)\n",
    "    text = re.sub(r\"(?is)<style.*?>.*?</style>\", \" \", text)\n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r\"(?s)<!--.*?-->\", \" \", text)\n",
    "    # Remove the remaining tag\n",
    "    text = re.sub(r\"(?s)<[^>]+>\", \" \", text)\n",
    "    # Remove prefixed b\n",
    "    text = re.sub(r\"^\\s*b[\\\"'](.+?)[\\\"']\\s*$\", r\"\\1\", text)\n",
    "    # Remove video\n",
    "    # text = re.sub(r\"\\s*\\[video\\]$\", r\"\\1\", text)    \n",
    "    # Remove end of the line characters\n",
    "    text = re.sub(r\"\\s*[\\[\\(][^\\]\\)]+[\\]\\)]\\s*$\", \"\", text)    \n",
    "    # Remove \\t from middle and end of the texts\n",
    "    text = re.sub(r\"\\b\\\\t\",\" \",text)\n",
    "    # Remove \\t from startof the texts\n",
    "    text = re.sub(r\"^\\\\t\",\" \",text)\n",
    "    # Remove all the special characters and numbers\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \" \", text)\n",
    "    # Remove all single characters\n",
    "    text = re.sub(r\"\\b[A-Za-z]\\b\", \" \", text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r\"^[A-Za-z]\\s+\", \" \", text)\n",
    "    # Substitute multiple spaces with single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "punct_pattern = f\"[{re.escape(string.punctuation)}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_text'] = data['text'].astype(str).apply(lambda x: clean_html_text(x))\n",
    "data['pre_text'] = data['pre_text'].astype(str).apply(lambda x: re.sub(punct_pattern, \"\", x))\n",
    "data['pre_text'] = data['pre_text'].astype(str).apply(lambda x: word_tokenize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_text'] = data['pre_text'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = {}\n",
    "\n",
    "for lista in data['pre_text']:\n",
    "    for word in lista:\n",
    "        if bag_of_words == 0:\n",
    "            bag_of_words[word] = 1\n",
    "        elif word in bag_of_words:\n",
    "            bag_of_words[word] +=1\n",
    "        else:\n",
    "            bag_of_words[word] = 1\n",
    "\n",
    "print(sorted(bag_of_words.items(), key=lambda x: -x[1])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_filter = ['video','says', 'tweets', 'tells','screenshots',\n",
    "                   'details', 'fck', 'btch', 'images', 'cck', 'image'\n",
    "                   ,'videos','ahole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pre_text_filter'] = data['pre_text'].apply(lambda tokens: [word for word in tokens if word not in words_to_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = {}\n",
    "\n",
    "for lista in data['pre_text_filter']:\n",
    "    for word in lista:\n",
    "        if bag_of_words == 0:\n",
    "            bag_of_words[word] = 1\n",
    "        elif word in bag_of_words:\n",
    "            bag_of_words[word] +=1\n",
    "        else:\n",
    "            bag_of_words[word] = 1\n",
    "\n",
    "print(sorted(bag_of_words.items(), key=lambda x: -x[1])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Using Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['snow_text'] = data['pre_text'].apply(lambda tokens: [snowball.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['porter_text'] = data['pre_text'].apply(lambda tokens: [porter.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Using Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text'] = data['pre_text'].apply(lambda tokens: [lemm.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Spliting the data into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Using only the preprocessed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['pre_text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## Using the preprocessed text + snow stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_snow, X_test_snow, y_train_snow, y_test_snow = train_test_split(X['snow_text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Using the preprocessed text + porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_porter, X_test_porter, y_train_porter, y_test_porter = train_test_split(X['porter_text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## Using the preprocessed text + noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filt, X_test_filt, y_train_filt, y_test_filt = train_test_split(X['pre_text_filter'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Using the preprocessed text + lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lemm, X_test_lemm, y_train_lemm, y_test_lemm = train_test_split(X['lemm_text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "# Training some classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Only preprocessed text - Best(TF-IDF Passive Agressive Classifier - Acc: 91.27 %, Gini: 94.29 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### TF-IDF - Best (Passive Agressive Classifier - Acc: 91.27 %, Gini: 94.29 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_tfidf, y_train)\n",
    "y_hat = dt_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_tfidf, y_train)\n",
    "y_hat = log_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_tfidf, y_train)\n",
    "y_hat = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_tfidf, y_train)\n",
    "y_hat = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_tfidf, y_train)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_tfidf)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "#### BoW - Best (Naive Bayes - Acc: 93.01 %, Gini: 85.98 % )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_bow, y_train)\n",
    "y_hat = dt_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_bow, y_train)\n",
    "y_hat = log_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_bow, y_train)\n",
    "y_hat = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_bow, y_train)\n",
    "y_hat = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_bow, y_train)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_bow)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Preprocessed text + noise removal - Best(TF-IDF Passive Agressive Classifier - Acc: 91.21 %, Gini: 93.88 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### TF-IDF - Best (Passive Agressive Classifier - Acc: 91.21 %, Gini: 93.88 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_train_filt)\n",
    "X_test_tfidf = vectorizer.transform(X_test_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_tfidf, y_train_filt)\n",
    "y_hat = dt_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_tfidf, y_train_filt)\n",
    "y_hat = log_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_tfidf, y_train_filt)\n",
    "y_hat = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_tfidf, y_train_filt)\n",
    "y_hat = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_tfidf, y_train_filt)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_tfidf)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "#### BoW - Best (Passive Agressive Classifier - Acc: 90.95 %, Gini: 93.68 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(X_train_filt)\n",
    "X_test_bow = vectorizer.transform(X_test_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_bow, y_train_filt)\n",
    "y_hat = dt_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_bow, y_train_filt)\n",
    "y_hat = log_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_bow, y_train_filt)\n",
    "y_hat = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_bow, y_train_filt)\n",
    "y_hat = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_bow, y_train_filt)\n",
    "y_hat = pac.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_filt, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_filt, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_filt, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_bow)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_filt, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "### Preprocessed text + snow stemmer - Best(TF-IDF Passive Agressive Classifier - Acc: 90.54 %, Gini: 93.15 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "#### TF-IDF - Best (Passive Agressive Classifier - Acc: 90.54 %, Gini: 93.15 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_train_snow)\n",
    "X_test_tfidf = vectorizer.transform(X_test_snow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_tfidf, y_train_snow)\n",
    "y_hat = dt_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_tfidf, y_train_snow)\n",
    "y_hat = log_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_tfidf, y_train_snow)\n",
    "y_hat = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_tfidf, y_train_snow)\n",
    "y_hat = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_tfidf, y_train_snow)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_tfidf)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "#### BoW - Best (Passive Agressive Classifier - Acc: 90.26 %, Gini: 93.18 % )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(X_train_snow)\n",
    "X_test_bow = vectorizer.transform(X_test_snow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_bow, y_train_snow)\n",
    "y_hat = dt_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_bow, y_train_snow)\n",
    "y_hat = log_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_bow, y_train_snow)\n",
    "y_hat = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_bow, y_train_snow)\n",
    "y_hat = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_bow, y_train_snow)\n",
    "y_hat = pac.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_snow, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_snow, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_snow, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_bow)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "### Preprocessed text + porter stemmer - Best(TF-IDF Passive Agressive Classifier - Acc: 91.24 %, Gini: 93.65 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "#### TF-IDF - Best (Passive Agressive Classifier - Acc: 91.24 %, Gini: 93.65 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_train_porter)\n",
    "X_test_tfidf = vectorizer.transform(X_test_porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_tfidf, y_train_porter)\n",
    "y_hat = dt_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_tfidf, y_train_porter)\n",
    "y_hat = log_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_tfidf, y_train_porter)\n",
    "y_hat = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_tfidf, y_train_porter)\n",
    "y_hat = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_tfidf, y_train_porter)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_tfidf)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "#### BoW - Best (Passive Agressive Classifier - Acc: 90.48 %, Gini: 93.17 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(X_train_porter)\n",
    "X_test_bow = vectorizer.transform(X_test_porter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_bow, y_train_porter)\n",
    "y_hat = dt_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_bow, y_train_porter)\n",
    "y_hat = log_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_bow, y_train_porter)\n",
    "y_hat = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_bow, y_train_porter)\n",
    "y_hat = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_snow, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_bow, y_train_porter)\n",
    "y_hat = pac.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_porter, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_porter, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_porter, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_bow)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_porter, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "### Preprocessed text + lemmatizer - Best (Passive Agressive Classifier - Acc: 91.56 %, Gini: 94.03 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152",
   "metadata": {},
   "source": [
    "#### TF-IDF - Best (Passive Agressive Classifier - Acc: 91.56 %, Gini: 94.03 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X_train_lemm)\n",
    "X_test_tfidf = vectorizer.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_tfidf, y_train_lemm)\n",
    "y_hat = dt_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_tfidf, y_train_lemm)\n",
    "y_hat = log_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_tfidf, y_train_lemm)\n",
    "y_hat = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_tfidf, y_train_lemm)\n",
    "y_hat = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_tfidf), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_tfidf, y_train_lemm)\n",
    "y_hat = pac.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_tfidf)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "#### BoW - Best (Passive Agressive Classifier - Acc: 91.36 %, Gini: 93.7 % )¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    lowercase=False\n",
    ")\n",
    "\n",
    "X_bow = vectorizer.fit_transform(X_train_lemm)\n",
    "X_test_bow = vectorizer.transform(X_test_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "##### Decision Tree metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=42).fit(X_bow, y_train_lemm)\n",
    "y_hat = dt_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(dt_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168",
   "metadata": {},
   "source": [
    "##### Logistic Regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_classifier = LogisticRegression(random_state=42).fit(X_bow, y_train_lemm)\n",
    "y_hat = log_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(log_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170",
   "metadata": {},
   "source": [
    "##### Naive Bayes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_bow, y_train_lemm)\n",
    "y_hat = nb_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(nb_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172",
   "metadata": {},
   "source": [
    "##### Random Forest metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_bow, y_train_lemm)\n",
    "y_hat = rf_classifier.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = np.argmax(rf_classifier.predict_proba(X_test_bow), axis=1)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174",
   "metadata": {},
   "source": [
    "##### PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50, random_state=42, n_jobs=-1).fit(X_bow, y_train_lemm)\n",
    "y_hat = pac.predict(X_test_bow)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_lemm, y_hat))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_lemm, y_hat))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test_lemm, y_hat))\n",
    "\n",
    "y_proba = pac.decision_function(X_test_bow)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_proba)\n",
    "print('Gini coef.:', 2*(auc(fpr, tpr))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177",
   "metadata": {},
   "outputs": [],
   "source": [
    "%paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# - DATA PREP\n",
    "\n",
    "MAX_VOCAB = 20000\n",
    "MAX_LEN = 300\n",
    "\n",
    "# Create and train the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB)\n",
    "tokenizer.fit_on_texts(X_train_lemm) # Learn from training text\n",
    "\n",
    "# Convert text to numbers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_lemm)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_lemm)\n",
    "\n",
    "# Padding -all sequences same length-\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Get real vocab size for the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(f\"Data ready. Train shape: {X_train_pad.shape}\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "\n",
    "# - MODEL DEFINITION\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=100, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(64, return_sequence=False)),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', # for True/False\n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# - TRAIN\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train_lemm,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_pad, y_test_lemm))\n",
    "\n",
    "# Predict\n",
    "y_pred_keras = model.predict(X_test_pad).ravel()\n",
    "\n",
    "# Geni\n",
    "fpr, tpr, thresholds = roc_curve(y_test_lemm, y_pred_keras)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "gini = 2 * roc_auc - 1\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Gini Coefficient: {gini:.4f}\")\n",
    "\n",
    "acc = history.history['val_accuracy'][-1]\n",
    "loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(\"Validation Accuracy:\", acc)\n",
    "print(\"Validation Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
